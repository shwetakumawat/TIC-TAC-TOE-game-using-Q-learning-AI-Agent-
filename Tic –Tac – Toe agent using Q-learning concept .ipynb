{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before learning:\n",
      "    percentage results: {'X': 58.53, 'O': 28.93, '-': 12.54}\n",
      "After 1000 learning games:\n",
      "    percentage results: {'X': 57.42, 'O': 31.06, '-': 11.52}\n",
      "After 5000 learning games:\n",
      "    percentage results: {'X': 15.79, 'O': 7.2, '-': 77.01}\n",
      "After 10000 learning games:\n",
      "    percentage results: {'X': 2.49, 'O': 0.64, '-': 96.87}\n",
      "After 20000 learning games:\n",
      "    percentage results: {'X': 0.22, 'O': 0.0, '-': 99.78}\n",
      "After 30000 learning games:\n",
      "    percentage results: {'X': 0.0, 'O': 0.0, '-': 100.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "from itertools import groupby\n",
    "\n",
    "class TicTacToeGame():\n",
    "    def __init__(self):\n",
    "        self.state = '         '\n",
    "        self.player = 'X'\n",
    "        self.winner = None\n",
    "\n",
    "    def allowed_moves(self):\n",
    "        states = []\n",
    "        for i in range(len(self.state)):\n",
    "            if self.state[i] == ' ':\n",
    "                states.append(self.state[:i] + self.player + self.state[i+1:])\n",
    "        return states\n",
    "\n",
    "    def make_move(self, next_state):\n",
    "        if self.winner:\n",
    "            raise(Exception(\"Game already completed, cannot make another move!\"))\n",
    "        if not self.__valid_move(next_state):\n",
    "            raise(Exception(\"Cannot make move {} to {} for player {}\".format(\n",
    "                    self.state, next_state, self.player)))\n",
    "\n",
    "        self.state = next_state\n",
    "        self.winner = self.predict_winner(self.state)\n",
    "        if self.winner:\n",
    "            self.player = None\n",
    "        elif self.player == 'X':\n",
    "            self.player = 'O'\n",
    "        else:\n",
    "            self.player = 'X'\n",
    "\n",
    "    def playable(self):\n",
    "        return ( (not self.winner) and any(self.allowed_moves()) )\n",
    "\n",
    "    def predict_winner(self, state):\n",
    "        lines = [(0,1,2), (3,4,5), (6,7,8), (0,3,6), (1,4,7), (2,5,8), (0,4,8), (2,4,6)]\n",
    "        winner = None\n",
    "        for line in lines:\n",
    "            line_state = state[line[0]] + state[line[1]] + state[line[2]]\n",
    "            if line_state == 'XXX':\n",
    "                winner = 'X'\n",
    "            elif line_state == 'OOO':\n",
    "                winner = 'O'\n",
    "        return winner\n",
    "\n",
    "    def __valid_move(self, next_state):\n",
    "        allowed_moves = self.allowed_moves()\n",
    "        if any(state == next_state for state in allowed_moves):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def print_board(self):\n",
    "        s = self.state\n",
    "        print('     {} | {} | {} '.format(s[0],s[1],s[2]))\n",
    "        print('    -----------')\n",
    "        print('     {} | {} | {} '.format(s[3],s[4],s[5]))\n",
    "        print('    -----------')\n",
    "        print('     {} | {} | {} '.format(s[6],s[7],s[8]))\n",
    "\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, game_class, epsilon=0.1, alpha=0.5, value_player='X'):\n",
    "        self.V = dict()\n",
    "        self.NewGame = game_class\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.value_player = value_player\n",
    "\n",
    "    def state_value(self, game_state):\n",
    "        return self.V.get(game_state, 0.0)\n",
    "\n",
    "    def learn_game(self, num_episodes=1000):\n",
    "        for episode in range(num_episodes):\n",
    "            self.learn_from_episode()\n",
    "\n",
    "    def learn_from_episode(self):\n",
    "        game = self.NewGame()\n",
    "        _, move = self.learn_select_move(game)\n",
    "        while move:\n",
    "            move = self.learn_from_move(game, move)\n",
    "\n",
    "    def learn_from_move(self, game, move):\n",
    "        game.make_move(move)\n",
    "        r = self.__reward(game)\n",
    "        td_target = r\n",
    "        next_state_value = 0.0\n",
    "        selected_next_move = None\n",
    "        if game.playable():\n",
    "            best_next_move, selected_next_move = self.learn_select_move(game)\n",
    "            next_state_value = self.state_value(best_next_move)\n",
    "        current_state_value = self.state_value(move)\n",
    "        td_target = r + next_state_value\n",
    "        self.V[move] = current_state_value + self.alpha * (td_target - current_state_value)\n",
    "        return selected_next_move\n",
    "\n",
    "    def learn_select_move(self, game):\n",
    "        allowed_state_values = self.__state_values( game.allowed_moves() )\n",
    "        if game.player == self.value_player:\n",
    "            best_move = self.__argmax_V(allowed_state_values)\n",
    "        else:\n",
    "            best_move = self.__argmin_V(allowed_state_values)\n",
    "\n",
    "        selected_move = best_move\n",
    "        if random.random() < self.epsilon:\n",
    "            selected_move = self.__random_V(allowed_state_values)\n",
    "\n",
    "        return (best_move, selected_move)\n",
    "\n",
    "    def play_select_move(self, game):\n",
    "        allowed_state_values = self.__state_values( game.allowed_moves() )\n",
    "        if game.player == self.value_player:\n",
    "            return self.__argmax_V(allowed_state_values)\n",
    "        else:\n",
    "            return self.__argmin_V(allowed_state_values)\n",
    "\n",
    "    def demo_game(self, verbose=False):\n",
    "        game = self.NewGame()\n",
    "        t = 0\n",
    "        while game.playable():\n",
    "            if verbose:\n",
    "                print(\" \\nTurn {}\\n\".format(t))\n",
    "                game.print_board()\n",
    "            move = self.play_select_move(game)\n",
    "            game.make_move(move)\n",
    "            t += 1\n",
    "        if verbose:\n",
    "            print(\" \\nTurn {}\\n\".format(t))\n",
    "            game.print_board()\n",
    "        if game.winner:\n",
    "            if verbose:\n",
    "                print(\"\\n{} is the winner!\".format(game.winner))\n",
    "            return game.winner\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"\\nIt's a draw!\")\n",
    "            return '-'\n",
    "\n",
    "    def interactive_game(self, agent_player='X'):\n",
    "        game = self.NewGame()\n",
    "        t = 0\n",
    "        while game.playable():\n",
    "            print(\" \\nTurn {}\\n\".format(t))\n",
    "            game.print_board()\n",
    "            if game.player == agent_player:\n",
    "                move = self.play_select_move(game)\n",
    "                game.make_move(move)\n",
    "            else:\n",
    "                move = self.__request_human_move(game)\n",
    "                game.make_move(move)\n",
    "            t += 1\n",
    "\n",
    "        print(\" \\nTurn {}\\n\".format(t))\n",
    "        game.print_board()\n",
    "\n",
    "        if game.winner:\n",
    "            print(\"\\n{} is the winner!\".format(game.winner))\n",
    "            return game.winner\n",
    "        print(\"\\nIt's a draw!\")\n",
    "        return '-'\n",
    "\n",
    "    def round_V(self):\n",
    "        # After training, this makes action selection random from equally-good choices\n",
    "        for k in self.V.keys():\n",
    "            self.V[k] = round(self.V[k],1)\n",
    "\n",
    "    def save_v_table(self):\n",
    "        with open('state_values.csv', 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(['State', 'Value'])\n",
    "            all_states = list(self.V.keys())\n",
    "            all_states.sort()\n",
    "            for state in all_states:\n",
    "                writer.writerow([state, self.V[state]])\n",
    "\n",
    "    def __state_values(self, game_states):\n",
    "        return dict((state, self.state_value(state)) for state in game_states)\n",
    "\n",
    "    def __argmax_V(self, state_values):\n",
    "        max_V = max(state_values.values())\n",
    "        chosen_state = random.choice([state for state, v in state_values.items() if v == max_V])\n",
    "        return chosen_state\n",
    "\n",
    "    def __argmin_V(self, state_values):\n",
    "        min_V = min(state_values.values())\n",
    "        chosen_state = random.choice([state for state, v in state_values.items() if v == min_V])\n",
    "        return chosen_state\n",
    "\n",
    "    def __random_V(self, state_values):\n",
    "        return random.choice(list(state_values.keys()))\n",
    "\n",
    "    def __reward(self, game):\n",
    "        if game.winner == self.value_player:\n",
    "            return 1.0\n",
    "        elif game.winner:\n",
    "            return -1.0\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    def __request_human_move(self, game):\n",
    "        allowed_moves = [i+1 for i in range(9) if game.state[i] == ' ']\n",
    "        human_move = None\n",
    "        while not human_move:\n",
    "            idx = int(input('Choose move for {}, from {} : '.format(game.player, allowed_moves)))\n",
    "            if any([i==idx for i in allowed_moves]):\n",
    "                human_move = game.state[:idx-1] + game.player + game.state[idx:]\n",
    "        return human_move\n",
    "\n",
    "def demo_game_stats(agent):\n",
    "    results = [agent.demo_game() for i in range(10000)]\n",
    "    game_stats = {k: results.count(k)/100 for k in ['X', 'O', '-']}\n",
    "    print(\"    percentage results: {}\".format(game_stats))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    agent = Agent(TicTacToeGame, epsilon = 0.1, alpha = 1.0)\n",
    "    print(\"Before learning:\")\n",
    "    demo_game_stats(agent)\n",
    "\n",
    "    agent.learn_game(1000)\n",
    "    print(\"After 1000 learning games:\")\n",
    "    demo_game_stats(agent)\n",
    "\n",
    "    agent.learn_game(4000)\n",
    "    print(\"After 5000 learning games:\")\n",
    "    demo_game_stats(agent)\n",
    "\n",
    "    agent.learn_game(5000)\n",
    "    print(\"After 10000 learning games:\")\n",
    "    demo_game_stats(agent)\n",
    "\n",
    "    agent.learn_game(10000)\n",
    "    print(\"After 20000 learning games:\")\n",
    "    demo_game_stats(agent)\n",
    "\n",
    "    agent.learn_game(10000)\n",
    "    print(\"After 30000 learning games:\")\n",
    "    demo_game_stats(agent)\n",
    "\n",
    "    agent.round_V()\n",
    "    agent.save_v_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
